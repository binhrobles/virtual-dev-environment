---

- hosts: localhost
  connection: local
  gather_facts: false

  vars:
    region: us-east-1
    instance_type: t4g.medium
    image: ami-07ce5684ee3b5482c # ripped from the AWS console
    architecture: arm
    security_group: vdev
    key_name: vdev
    instance_name: vdev-instance
    volume_name: vdev-volume
    instance_profile_name: vdev-instance-profile

  tasks:
    - name: Provision vdev environment
      # Require the 'provision' tag to provision the env
      tags: ['never', 'provision']
      block:

        - name: Create security group
          tags: ['never', 'provision', 'sg']
          amazon.aws.ec2_security_group:
            name: "{{ security_group }}"
            description: SG for virtual dev environment
            region: "{{ region }}"
            rules:
              - proto: tcp
                ports:
                  - 22
                  - 3000
                  - 3333
                  - 8000
                cidr_ip: 0.0.0.0/0
                rule_desc: allow all on ssh port, dev ports

        - name: Create key pair
          amazon.aws.ec2_key:
            name: "{{ key_name }}"
            region: "{{ region }}"
            key_material: "{{ item }}"
          with_file: /home/binhrobles/.ssh/vdev.pub

        - name: Create instance profile role and attach a managed policy
          community.aws.iam_role:
            name: "{{ instance_profile_name }}"
            assume_role_policy_document: "{{ lookup('file','iam_instance_trust_policy.json') }}"
            managed_policies:
              - arn:aws:iam::aws:policy/CloudWatchAgentServerPolicy

        - name: Start an instance
          amazon.aws.ec2_instance:
            name: "{{ instance_name }}"
            key_name: "{{ key_name }}"
            instance_type: "{{ instance_type }}"
            security_group: "{{ security_group }}"
            region: "{{ region }}"
            image_id: "{{ image }}"
            iam_instance_profile: "{{ instance_profile_name }}"
            wait: true
          register: ec2

        - name: Associate static Elastic IP
          amazon.aws.ec2_eip:
            device_id: "{{ ec2.instances[0].instance_id }}"

          # some idempotency issues here
        - name: Create / Attach EBS volume
          ignore_errors: true
          amazon.aws.ec2_vol:
            instance: "{{ ec2.instances[0].instance_id }}"
            name: "{{ volume_name }}"
            device_name: /dev/sdf
            volume_type: gp3
            volume_size: 30
            delete_on_termination: true
        
        # TODO?: set up auto shutdown

        - name: Get vdev facts
          amazon.aws.ec2_instance_info:
            filters:
              "tag:Name": vdev-instance
          register: ec2

        - name: Instance info
          debug:
            msg: "ID: {{ ec2.instances[0].instance_id }} - State: {{ ec2.instances[0].state.name }} - Public DNS: {{ ec2.instances[0].public_dns_name }}"

    - name: Stop vdev instance
      tags: ['never', 'stop']
      amazon.aws.ec2_instance:
        name: vdev-instance
        state: stopped
    
    - name: Start vdev instance
      tags: ['never', 'start']
      amazon.aws.ec2_instance:
        name: vdev-instance
        state: running

    - name: Nuke vdev environment completely
      # Require the 'nuke' tag to nuke the env
      tags: ['never', 'nuke']
      block:

        - name: Get vdev facts
          amazon.aws.ec2_instance_info:
            filters:
              "tag:Name": vdev-instance
          register: ec2

        - name: Release Elastic IP
          amazon.aws.ec2_eip:
            device_id: "{{ ec2.instances[0].instance_id }}"
            state: absent

        - name: Kill vdev instance
          amazon.aws.ec2_instance:
            name: vdev-instance
            state: absent

        - name: Destroy instance profile
          community.aws.iam_role:
            name: "{{ instance_profile_name }}"
            assume_role_policy_document: "{{ lookup('file','iam_instance_trust_policy.json') }}"
            state: absent

        - name: Destroy security group
          amazon.aws.ec2_security_group:
            name: "{{ security_group }}"
            state: absent

        - name: Destroy key pair
          amazon.aws.ec2_key:
            name: "{{ key_name }}"
            region: "{{ region }}"
            state: absent

- hosts: tag_Name_vdev_instance
  gather_facts: false

  tasks:
    - name: Set up dev environment
      tags: ['never', 'configure']
      block:

        - name: Install yum dependencies
          become: true
          yum:
            name:
              - git
              - gcc-c++
              - make
              - tmux
              - amazon-cloudwatch-agent
              - yum-utils
              - shadow-utils
              - docker
            state: present

        - name: Copy tmux config
          copy:
            src: tmux.conf
            dest: /home/ec2-user/.tmux.conf
            owner: ec2-user
            group: ec2-user
            mode: 0644

        # add hashicorp to yum repos
        # for some reason, yum_repository adds the repo, 
        # but yum install terraform won't work
        - name: Add hashicorp repository
          become: true
          command: 
            cmd: yum-config-manager --add-repo https://rpm.releases.hashicorp.com/AmazonLinux/hashicorp.repo
            creates: /etc/yum.repos.d/hashicorp.repo

        # install terraform
        - name: Install Terraform
          become: true
          yum:
            name: terraform
            state: present

        - name: Copy CloudWatch config
          become: true
          copy:
            src: amazon-cloudwatch-agent.json
            dest: /opt/aws/amazon-cloudwatch-agent/etc/amazon-cloudwatch-agent.json
            owner: cwagent
            group: cwagent
            mode: 0644
          register: cw_config

        - name: Start CloudWatch agent
          become: true
          command: /opt/aws/amazon-cloudwatch-agent/bin/amazon-cloudwatch-agent-ctl -a fetch-config -m ec2 -c file:/opt/aws/amazon-cloudwatch-agent/etc/amazon-cloudwatch-agent.json -s
          when: cw_config.changed

        - name: mount file system
          become: true
          shell:
            cmd: |
              mkfs -t xfs /dev/sdf
              mkdir /workspace
              mount /dev/sdf /workspace
              chmod 700 /workspace
              chown ec2-user:ec2-user /workspace
              ln -s /workspace .
            creates: /workspace

        - name: Install Node.js via nvm + enable Yarn via corepack
          shell:
            cmd: |
              curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.7/install.sh | bash
              source ~/.bashrc
              nvm install --lts
              nvm use --lts
              corepack enable
            creates: /home/ec2-user/.nvm/alias
